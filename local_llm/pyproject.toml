[build-system]
requires = ["setuptools>=61.0", "wheel"]
build-backend = "setuptools.build_meta"

[project]
name = "local-llm"
version = "0.1.0"
description = "Local LLM service using Ollama with OpenAI-compatible API"
readme = "README.md"
requires-python = ">=3.8"
authors = [
    {name = "Your Name", email = "your.email@example.com"}
]
dependencies = [
    "openai>=1.12.0",
    "ollama>=0.4.0",
    "httpx>=0.25.0",
]

[project.optional-dependencies]
dev = [
    "pytest>=7.0.0",
    "pytest-asyncio>=0.21.0",
]

[project.scripts]
local-llm-setup = "local_llm.setup_models:main"
local-llm-health = "local_llm.health:main"

[tool.setuptools.packages.find]
where = ["."]
include = ["local_llm*"]
